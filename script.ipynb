!pip install nltk
!pip install transformers
!pip install torch
import nltk
from nltk.tokenize import word_tokenize
import difflib
import torch
from transformers import GPT2LMHeadModel, GPT2Tokenizer

# Download the necessary NLTK resources if not already downloaded
nltk.download('punkt')
nltk.download('words')

# Load the GPT-2 model and tokenizer
model = GPT2LMHeadModel.from_pretrained('gpt2')
tokenizer = GPT2Tokenizer.from_pretrained('gpt2')

# Set the device to use (e.g., 'cuda' for GPU or 'cpu' for CPU)
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)
model.eval()

def heal_token(token):
    # Check if the token is a valid word or needs healing
    if is_valid_word(token):
        return token
    else:
        best_match = get_best_match(token)
        if best_match is not None:
            return best_match
        else:
            return token

def is_valid_word(token):
    # Check if the token is a valid word
    return token in nltk.corpus.words.words()

def get_best_match(token):
    matches = difflib.get_close_matches(token, nltk.corpus.words.words(), n=1, cutoff=0.8)
    if matches:
        return matches[0]
    else:
        return None

def token_healing(text):
    # Tokenize the input text into a list of tokens
    tokens = word_tokenize(text)

    # Iterate over each token and perform token healing
    for i in range(len(tokens)):
        tokens[i] = heal_token(tokens[i])

    # Check if the last token is a punctuation mark
    if tokens and tokens[-1] == ',':
        tokens[-1] = '?'

    # Reconstruct the healed text from the tokens
    healed_text = ' '.join(tokens)

    return healed_text

# Prompt the user to enter a sentence
input_text = input("Enter a sentence: ")

# Perform token healing on the input
healed_text = token_healing(input_text)

# Tokenize the healed text
input_ids = tokenizer.encode(healed_text, add_special_tokens=True, return_tensors='pt').to(device)

# Generate missing words using the language model
with torch.no_grad():
    output = model.generate(input_ids, max_length=20, num_return_sequences=1)

# Decode the generated output
generated_text = tokenizer.decode(output[0], skip_special_tokens=True)

print("Healed sentence:", healed_text)
print("Generated text:", generated_text)
